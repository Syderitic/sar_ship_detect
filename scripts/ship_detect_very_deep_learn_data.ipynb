{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for very deep learning\n",
    "Data [here:](https://gitlab.com/sarmaps/sar-ship-dataset)\n",
    "\n",
    "Article [here:](https://sci-hub.ren/10.1109/igarss.2016.7729017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to the data\n",
    "PATH = r'C:\\Users\\arman\\Documents\\GitHub\\sar_ship_detect'\n",
    "#data_path = join(os. getcwd(), '..','data', 'Iceberg-classifier-challenge')\n",
    "data_path = join(PATH, 'data', 'very_deep_learn_data', 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false_positives.json', 'ship_positives.json', 'true_negatives.json']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA DESCRIPTION\n",
    "A SAR dataset has been created using 22 Sentinel-1 (Extra\n",
    "Wide Swath) and 3 RADARSAT-2 (Scan-SAR Narrow) acquisition with a total of 42 dual and 4 single polarized, radiometrically calibrated images. The dataset covers approximately 80% of the South African Exclusive Economic Zone (EEZ) with multiple acquisitions over a number of harbours (high ship densities). For this experiment, the dataset was analysed and split into three classes of `21 × 21` sub-images, containing **ships** (`positives`), **ship-like areas** (`false positives`) and **ocean areas** (`negatives`). The usefulness of splitting the samples up into three classes is that it now allows for a more descriptive analysis of how various methods deal with `ship lookalikes` and open ocean areas. The `1596 positive examples` were identified using expert analysis with each ship having an associated ground truth image not used in this experiment. The false positive sub-images were generated by selecting areas that did not contain ships but were incorrectly highlighted by a `low-threshold cell-averaging constant false alarm rate` (CA-CFAR). This lowthreshold approach was done to generate as many samples as possible for future experiments. Of the approximate 500 000 false positive sub-images extracted across the 46 images, `3192 false positive` images were selected at random. This is twice as many as the positive examples and represents the distribution of false positives to positives that would be encountered with careful prescreening threshold design and selection. Finally, `1596 sub-images that did not contain either a ship or false positive` were selected as negative ocean samples. Depending on the selected prescreening method, the negative samples will often not be presented to the ship discrimination classifier. They are provided here, however, to train the classifier to handle negative samples. No additional feature extraction was performed on the 9588 sub-images resulting in input feature set of 21x21 normalized RCS pixel values per image․"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data.\n",
    "false_positives = pd.read_json(join(data_path, 'false_positives.json'))\n",
    "ship_positives = pd.read_json(join(data_path, 'ship_positives.json'))\n",
    "true_negatives = pd.read_json(join(data_path, 'true_negatives.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_positives:  (1, 1596)\n",
      "false_positives: (1, 6384)\n",
      "true_negatives:  (1, 1596)\n"
     ]
    }
   ],
   "source": [
    "print('true_positives: ',ship_positives.shape)\n",
    "print('false_positives:',false_positives.shape) # not corresponding to the data sescribtion, should be checked out\n",
    "print('true_negatives: ',true_negatives.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the beccessary data from the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extract(data_frame, dict_key):\n",
    "    \"\"\"Extract data from json file and \n",
    "    transform it as ndarray\"\"\"\n",
    "    #dict_key: should be text\n",
    "    \n",
    "    list_of_bands = []\n",
    "    for i in range(data_frame.shape[1]):\n",
    "        single_arr = data_frame[i][0][dict_key]\n",
    "        \n",
    "        # we need to recover the incidence angle as a band image\n",
    "        if dict_key == 'incidenceangle':\n",
    "            band = np.full((21, 21), single_arr)\n",
    "        else:\n",
    "            band = single_arr\n",
    "            \n",
    "        list_of_bands.append(band)\n",
    "\n",
    "    return np.array(list_of_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover the incidence angle as a band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get true positive data\n",
    "ship_positive_data = data_extract(ship_positives, 'windowfu')\n",
    "#ship_positive_target = data_extract(ship_positives, 'validais')\n",
    "ship_positive_angle = data_extract(ship_positives, 'incidenceangle')\n",
    "# define ship target cass as \"2\"\n",
    "ship_positive_target = np.full(ship_positives.shape[1], 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get false positive data\n",
    "false_positives_data = data_extract(false_positives, 'windowfu')\n",
    "false_positives_angle = data_extract(false_positives, 'incidenceangle')\n",
    "false_positives_target = data_extract(false_positives, 'thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get true negative data\n",
    "true_negatives_data = data_extract(true_negatives, 'windowfu')\n",
    "true_negatives_angle = data_extract(true_negatives, 'incidenceangle')\n",
    "true_negatives_target = data_extract(true_negatives, 'thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_data = np.concatenate([ship_positive_data, false_positives_data, true_negatives_data])\n",
    "angle_data = np.concatenate([ship_positive_angle, false_positives_angle, true_negatives_angle])\n",
    "target = np.concatenate([ship_positive_target, false_positives_target, true_negatives_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1596</td>\n",
       "      <td>6384</td>\n",
       "      <td>1596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2     1     0\n",
       "0  1596  6384  1596"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([dict(Counter(target))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([radar_data[:, :, :, np.newaxis], angle_data[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9576, 21, 21, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9576,)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'random noise')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize image samples\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#subplot(r,c) provide the no. of rows and columns\n",
    "f, axarr = plt.subplots(1,4, figsize=(15, 15)) \n",
    "\n",
    "# use the created array to output your multiple images. In this case I have stacked 4 images vertically\n",
    "axarr[0].imshow(ship_positive_data[1200,:,:], cmap=\"gray\")\n",
    "axarr[0].set_title('ship')\n",
    "axarr[1].imshow(ship_positive_data[14,:,:], cmap=\"gray\")  \n",
    "axarr[1].set_title('ship')\n",
    "axarr[2].imshow(false_positives_data[665,:,:], cmap=\"gray\")\n",
    "axarr[2].set_title('ship-like')\n",
    "axarr[3].imshow(true_negatives_data[121,:,:], cmap=\"gray\") \n",
    "axarr[3].set_title('random noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Keras.\n",
    "from matplotlib import pyplot\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, Conv1D, MaxPooling1D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.metrics import binary_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture modification\n",
    "\n",
    "CNN model is modified the way to handle with 2 input bands only and saller image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original model\n",
    "#define our model\n",
    "def getModel():\n",
    "    #Building the model\n",
    "    gmodel=Sequential()\n",
    "    #Conv Layer 1\n",
    "    #gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "    gmodel.add(Conv1D(64, kernel_size= 3,activation='relu', batch_input_shape =(21, 21, 2)))\n",
    "    gmodel.add(MaxPooling1D(pool_size= 3, strides=1))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 2\n",
    "    gmodel.add(Conv1D(128, kernel_size=3, activation='relu' ))\n",
    "    gmodel.add(MaxPooling1D(pool_size= 2, strides=1))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 3\n",
    "    gmodel.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "    gmodel.add(MaxPooling1D(pool_size= 2, strides=1))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Conv Layer 4\n",
    "    gmodel.add(Conv1D(64, kernel_size= 3, activation='relu'))\n",
    "    gmodel.add(MaxPooling1D(pool_size= 2, strides=1))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Flatten the data for upcoming dense layers\n",
    "    gmodel.add(Flatten())\n",
    "\n",
    "    #Dense Layers\n",
    "    gmodel.add(Dense(512))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Dense Layer 2\n",
    "    gmodel.add(Dense(256))\n",
    "    gmodel.add(Activation('relu'))\n",
    "    gmodel.add(Dropout(0.2))\n",
    "\n",
    "    #Sigmoid Layer\n",
    "    gmodel.add(Dense(1))\n",
    "    gmodel.add(Activation('sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    #mypotim = SGD(lr=0.01, momentum=0.9)\n",
    "    mypotim=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    gmodel.compile(loss='categorical_crossentropy',                             #binary_crossentropy\n",
    "                  optimizer=mypotim,\n",
    "                  metrics=['accuracy'])                                         # f1_score and g-mean to be implemented\n",
    "    gmodel.summary()\n",
    "    return gmodel\n",
    "\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "#file_path = \".model_weights.hdf5\"\n",
    "#file_path = \".model_weights_inc_angle_as_band.hdf5\"\n",
    "file_path = \".model_weights_very_deep_learn_ds.hdf5\"\n",
    "callbacks = get_callbacks(filepath=file_path, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data split: \n",
      "Train: \t   5362 \n",
      "Validation: 1341 \n",
      "Test: \t    2873\n"
     ]
    }
   ],
   "source": [
    "# Define the data split strategy\n",
    "def data_split(data, target, train_size, test_size): \n",
    "    ''' Train-validation-test split'''\n",
    "\n",
    "    # split data to get the initial training test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=1, \n",
    "                                                train_size=train_size, stratify = target)\n",
    "    \n",
    "    # split data to get train validation split\n",
    "    X_train_cv, X_valid, y_train_cv, y_valid = train_test_split( X_train, y_train, random_state=1,\n",
    "                                                test_size = valid_size, stratify = y_train) \n",
    "    \n",
    "    return  X_train_cv, X_valid, X_test, y_train_cv, y_valid, y_test\n",
    "\n",
    "# define split parameters\n",
    "train_size = 0.70\n",
    "valid_size = 0.20\n",
    "\n",
    "X_train_cv, X_valid, X_test, y_train_cv, y_valid, y_test = data_split(data, target, train_size, valid_size )\n",
    "print(f'data split: \\nTrain: \\t   {X_train_cv.shape[0]} \\nValidation: {X_valid.shape[0]} \\nTest: \\t    {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_19: expected ndim=3, found ndim=4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-265-47372d0d8e56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Without denoising, core features.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m gmodel.fit(X_train_cv, y_train_cv,\n\u001b[0;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-264-3ff0d7621abc>\u001b[0m in \u001b[0;36mgetModel\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#Conv Layer 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#gmodel.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mgmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_input_shape\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mgmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mgmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arman\\anaconda3\\envs\\ship_nn\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                     \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arman\\anaconda3\\envs\\ship_nn\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arman\\anaconda3\\envs\\ship_nn\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\arman\\anaconda3\\envs\\ship_nn\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_19: expected ndim=3, found ndim=4"
     ]
    }
   ],
   "source": [
    "#Without denoising, core features.\n",
    "gmodel=getModel()\n",
    "gmodel.fit(X_train_cv, y_train_cv,\n",
    "          batch_size=24,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

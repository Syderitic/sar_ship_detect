{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \\label{fig:coding}\n",
    "\n",
    "#This code is prepared to classify and recognize ship s on the\n",
    "#UAV generated images\n",
    "#Importing the basic libraries and modules\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator , load_img\n",
    "from keras.callbacks import ModelCheckpoint , EarlyStopping , CSVLogger\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense , Flatten\n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time() #Recording the time starts here\n",
    "#Defining the variables by assigning their path to the directories\n",
    "train_dir = ’/Thesis_Dataset/Train’\n",
    "validation_dir = ’/Thesis_Dataset/validate’\n",
    "test_dir = ’/Thesis_Dataset/Test’\n",
    "\n",
    "eval_dir = ’/hesis_Dataset/test_evaluation’\n",
    "\n",
    "image_size = 224\n",
    "\n",
    "#Load the VGG model , remember to assign false on top layers to remove it and\n",
    "#avoid the original 1000 classes of ImageNet to modify on our classes (i.e.5)\n",
    "vgg_conv = VGG16(weights=’imagenet’, include_top=False , input_shape=\n",
    "(image_size , image_size , 3))\n",
    "vgg_conv.summary()\n",
    "\n",
    "# Freeze/Unfreeze the layers\n",
    "# Freeze the layers: No specific rule (More as heat and trial)\n",
    "#but early layers are normally freezed (like edges ,)\n",
    "#whereas latter layers normally extract the specific \\\\properties of dataset.\n",
    "#for layer in vgg_conv.layers[:]: # No layers are freezed in this case\n",
    "# layer.trainable = True\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "#for layer in vgg_conv.layers:\n",
    "# print(layer , layer.trainable)\n",
    "\n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    "# Add the vgg convolutional base model\n",
    "model.add(vgg_conv)\n",
    "# Add new layers\n",
    "#Dropout value can be changed or removed\n",
    "#BatchNormalization can be added; it is considered good for robustness\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation=’relu’))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "#model.add(layers.Dense(512, activation=’relu’))\n",
    "#model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(5, activation=’softmax’))\n",
    "#Add a layer where input is the output of the second last layer\n",
    "#x = vgg_conv.output\n",
    "#x = Flatten()(x)\n",
    "#predictions = Dense(5, activation=’softmax’)(x)\n",
    "#model = Model(inputs=vgg_conv.input , outputs=predictions)\n",
    "#model.summary()\n",
    "\n",
    "#Data augmentation done here, these values can be changed.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\"\"\"\n",
    "rotation_range=2,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode=’nearest’)\n",
    "\"\"\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Change the batchsize according to your system RAM\n",
    "train_batchsize = 32\n",
    "val_batchsize = 16\n",
    "eval_batchsize=1\n",
    "# Data Generator for Training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir ,\n",
    "target_size=(image_size , image_size),\n",
    "batch_size=train_batchsize ,\n",
    "class_mode=’categorical’,\n",
    "shuffle=True)\n",
    "\n",
    "# Data Generator for Validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_dir ,\n",
    "target_size=(image_size , image_size),\n",
    "batch_size=val_batchsize ,\n",
    "class_mode=’categorical’,\n",
    "shuffle=False)\n",
    "# Compile the model\n",
    "##Activation Functions like ReLU, Tanh, LeakyReLU are available\n",
    "model.compile(loss=’categorical_crossentropy’,\n",
    "optimizer=optimizers.Adam(lr=1e-4),\n",
    "metrics=[’acc’])\n",
    "# This is to save the model according to the conditions and\n",
    "#stops if validation accuracy is not improving as per the assigned condition\n",
    "checkpoint = ModelCheckpoint(\"VGglast.h5\", monitor=’val_acc’,\n",
    "verbose=1, save_best_only=True, save_weights_only=False , mode=’auto’,\n",
    "period=1)\n",
    "early = EarlyStopping(monitor=’val_acc’, min_delta=0, patience=10,\n",
    "verbose=1, mode=’auto’)\n",
    "csv_logger = CSVLogger(\"vgglast.csv\", append=True)\n",
    "# Train the Model\n",
    "history = model.fit_generator(\n",
    "train_generator ,\n",
    "steps_per_epoch=train_generator.samples//train_generator.batch_size ,\n",
    "epochs=20 ,\n",
    "validation_data=validation_generator ,\n",
    "validation_steps=validation_generator.samples//\n",
    "validation_generator.batch_size ,\n",
    "callbacks = [checkpoint , early , csv_logger])\n",
    "\n",
    "# Save the Model\n",
    "#model.save(’last_elu4lyr_frze.h5’)\n",
    "import pickle\n",
    "with open(’vgglast’, ’wb’) as handle: # saving the history of the model\n",
    "pickle.dump(history.history , handle)\n",
    "\n",
    "print(\"%f\u0017seconds\" % (time.time() - start_time))\n",
    "#from keras.utils import plot_model\n",
    "#plot_model(model , to_file=’model.png’)\n",
    "# Plot the accuracy and loss curves\n",
    "acc = history.history[’acc’]\n",
    "val_acc = history.history[’val_acc’]\n",
    "loss = history.history[’loss’]\n",
    "val_loss = history.history[’val_loss’]\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs , acc, ’b’, label=’Training\u0017acc’)\n",
    "plt.plot(epochs , val_acc , ’r’, label=’Validation\u0017acc’)\n",
    "plt.title(’Training\u0017and\u0017validation\u0017accuracy’)\n",
    "plt.legend()\n",
    "plt.savefig(’vgglast_acc.png’)\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs , loss, ’b’, label=’Training\u0017loss’)\n",
    "plt.plot(epochs , val_loss , ’r’, label=’Validation\u0017loss’)\n",
    "plt.title(’Training\u0017and\u0017validation\u0017loss’)\n",
    "plt.legend()\n",
    "plt.savefig(’vgglast_loss.png’)\n",
    "plt.show()\n",
    "#plt.savefig([\"plot2.png\"])\n",
    "#Code below is to predict the validation accuracy and\n",
    "#then to obtain the confusion matrix. Depending upon accuracy on the\n",
    "#dataset we need we should use the related dataset generator.\n",
    "# Below is the prediction for validation data, we can switch it for\n",
    "# test dataset\n",
    "# as well by copying the code from lines created below for test generator)\n",
    "#and changing the validation_generator with test_generator\n",
    "\n",
    "#At first , evaluating the validation data! Should it be test data??\n",
    "start_time = time.time()\n",
    "evaluation_generator = test_datagen.flow_from_directory(\n",
    "    eval_dir ,\n",
    "    target_size=(image_size , image_size),\n",
    "    batch_size=eval_batchsize ,\n",
    "    class_mode=’categorical’,\n",
    "    shuffle=False)\n",
    "\n",
    "scores = model.evaluate_generator(evaluation_generator , steps = 596)\n",
    "print(’Loss:’, scores[0])\n",
    "print(’Accuracy:’, scores[1])\n",
    "\n",
    "print(\"%f\u0017seconds\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#For predicting accuracy\n",
    "179 # Get the filenames from the generator\n",
    "180 fnames = evaluation_generator.filenames\n",
    "181\n",
    "182 # Get the ground truth from generator\n",
    "183 ground_truth = evaluation_generator.classes\n",
    "184\n",
    "185 # Get the label to class mapping from the generator\n",
    "186 label2index = evaluation_generator.class_indices\n",
    "187\n",
    "188 # Getting the mapping from class index to class label\n",
    "189 idx2label = dict((v,k) for k,v in label2index.items())\n",
    "190\n",
    "191 # Get the predictions from the model using the generator\n",
    "192 predictions = model.predict_generator(evaluation_generator ,\n",
    "193 steps=evaluation_generator.samples/\n",
    "194 evaluation_generator.batch_size ,verbose=1)\n",
    "195 pred_class = np.argmax(predictions ,axis=1)\n",
    "196\n",
    "197 errors = np.where(pred_class != ground_truth)[0]\n",
    "198 print(\"No\u0017of\u0017errors\u0017=\u0017{}/{}\".format(len(errors),eval_generator.samples))\n",
    "199 \"\"\"\n",
    "200 #\u0017Show\u0017the\u0017errors\n",
    "201 for\u0017i\u0017in\u0017range(len(errors)):\n",
    "202 pred_class\u0017=\u0017np.argmax(predictions[errors[i]])\n",
    "203 pred_label\u0017=\u0017idx2label[pred_class]\n",
    "204\n",
    "205 title\u0017=\u0017’Original\u0017label:{},\u0017Prediction\u0017:{},\u0017confidence\u0017:\u0017{:.3f}’.format(\n",
    "206 fnames[errors[i]].split(’/’)[0],\n",
    "207 pred_label ,\n",
    "208 predictions[errors[i]][pred_class])\n",
    "209\n",
    "210 original\u0017=\u0017load_img(’{}/{}’.format(validation_dir ,fnames[errors[i]]))\n",
    "211 plt.figure(figsize=[7,7])\n",
    "212 plt.axis(’off’)\n",
    "213 plt.title(title)\n",
    "214 plt.imshow(original)\n",
    "215 plt.show()\n",
    "216 \"\"\"\n",
    "217 print(\"%f\u0017seconds\" % (time.time() - start_time))\n",
    "218\n",
    "219 #To save the prediction in excel sheet but since I am directly predicting\n",
    "220 #here Confusion matrix , it was not saved , may be useful in server to save it.\n",
    "221 import sklearn.metrics as metrics\n",
    "222 #pred_class = np.argmax(prob, axis=1)\n",
    "223 target_names = [’cargo’, ’no_ship’, ’ship_dinghies’,\n",
    "224 ’small_boat’, ’small_boat_patrol’]\n",
    "225 report = metrics.classification_report(ground_truth ,\n",
    "226 pred_class , target_names=target_names)\n",
    "227 print(report)\n",
    "\n",
    "import itertools\n",
    "230 #cm = confusion_matrix(idx2label , predictions )\n",
    "231 def plot_confusion_matrix(cm, classes ,\n",
    "232 normalize=False ,\n",
    "233 title=’Confusion\u0017matrix’,\n",
    "234 cmap=plt.cm.Blues):\n",
    "235 if normalize:\n",
    "236 cm = cm.astype(’float’) / cm.sum(axis=1)[:, np.newaxis]\n",
    "237 print(\"Normalized\u0017confusion\u0017matrix\")\n",
    "238 else:\n",
    "239 print(’Confusion\u0017matrix ,\u0017without\u0017normalization’)\n",
    "240\n",
    "241 #print(cm)\n",
    "242\n",
    "243 plt.imshow(cm, interpolation=’nearest’, cmap=cmap)\n",
    "244 plt.title(title)\n",
    "245 plt.colorbar()\n",
    "246 tick_marks = np.arange(len(classes))\n",
    "247 plt.xticks(tick_marks , classes , rotation=45)\n",
    "248 plt.yticks(tick_marks , classes)\n",
    "249\n",
    "250 fmt = ’.2f’ if normalize else ’d’\n",
    "251 thresh = cm.max() / 5.\n",
    "252 for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "253 plt.text(j, i, format(cm[i, j], fmt),\n",
    "254 horizontalalignment=\"center\",\n",
    "255 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "256\n",
    "257 plt.ylabel(’True\u0017label’)\n",
    "258 plt.xlabel(’Predicted\u0017label’)\n",
    "259 plt.tight_layout()\n",
    "260\n",
    "261\n",
    "262 # Compute confusion matrix\n",
    "263 cnf_matrix = confusion_matrix(ground_truth , pred_class)\n",
    "264 np.set_printoptions(precision=2)\n",
    "265 # Plot normalized confusion matrix\n",
    "266 plt.figure()\n",
    "267 plot_confusion_matrix(cnf_matrix , classes=target_names , normalize=False ,\n",
    "268 title=’Confusion\u0017matrix’)\n",
    "269\n",
    "270 plt.show()\n",
    "271 plt.savefig(’vgglast.png’)\n",
    "272\n",
    "273 print(\"%f\u0017seconds\" % (time.time() - start_time))\n",
    "274\n",
    "275\n",
    "276\n",
    "277 start_time = time.time()\n",
    "\n",
    "#To evaluate accuracy of the model with the test data\n",
    "279 test_generator = test_datagen.flow_from_directory(\n",
    "280 test_dir ,\n",
    "281 target_size=(image_size , image_size),\n",
    "282 batch_size=1,\n",
    "283 class_mode=None,\n",
    "284 shuffle=False)\n",
    "285\n",
    "286\n",
    "287 test_generator.reset()\n",
    "288 #Predicting for the test data\n",
    "289\n",
    "290 pred=model.predict_generator(test_generator , steps=\n",
    "291 test_generator.samples//test_generator.batch_size )\n",
    "292\n",
    "293 predicted_class_indices=np.argmax(pred, axis=1)\n",
    "294 labels = (train_generator.class_indices)\n",
    "295 labels=dict((v,k) for k,v in labels.items())\n",
    "296 predictions = [labels[k] for k in predicted_class_indices]\n",
    "297\n",
    "298 filenames=test_generator.filenames\n",
    "299 results=pd.DataFrame({\"Filename\":filenames ,\n",
    "300 \"Predictions\":predictions})\n",
    "301 results.to_csv(\"VGglast.csv\", index=True)\n",
    "302\n",
    "303 print(\"%f\u0017seconds\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
